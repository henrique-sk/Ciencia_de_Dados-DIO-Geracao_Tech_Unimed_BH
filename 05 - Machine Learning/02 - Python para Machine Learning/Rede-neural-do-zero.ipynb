{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d2b5eff-d476-443d-8b12-304f993e79e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# para executar no Colab não precisa rodar esta célula\n",
    "\n",
    "# para utilizar o pytorch no Jupyter, consultar https://pytorch.org, fornecer as configs de hardware e software e utilizar a instalação conforme orientado no site\n",
    "# conda install pytorch torchvision torchaudio pytorch-cuda=11.7 -c pytorch -c nvidia\n",
    "\n",
    "# para utilizar o opencv no Jupyter, instalar o opencv:\n",
    "# pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e125d52-1f12-45e4-bef1-bfa8992a39e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8f88a5a-5afe-44ab-8e86-572b12d96d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.ToTensor() #definindo a conversão de imagem para tensor\n",
    "\n",
    "trainset = datasets.MNIST('./MNIST_data/', download=True, train=True, transform=transform) # Carrega a parte de treino do dataset\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True) # Cria um buffer para pegar os dados por partes\n",
    "\n",
    "valset = datasets.MNIST('./MNIST_data/', download=True, train=False, transform=transform) # Carrega a parte de validação do dataset\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=64, shuffle=True) # Cria um buffer para pegar os dados por partes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e72e5f5-e6f9-4a3f-9f74-aec09377509f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "imagens, etiquetas = next(dataiter)\n",
    "# ou\n",
    "# imagens, etiquetas = dataiter.next()\n",
    "plt.imshow(imagens[0].numpy().squeeze(), cmap='gray_r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5dfa0b1a-8e1b-4315-b1d2-ed65f5e6d1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "torch.Size([])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(imagens[0].shape) # para verificar as dimensões do tensor de cada imagem\n",
    "print(etiquetas[0].shape) # para verificar as dimensões do tensor de cada etiqueta\n",
    "\n",
    "torch.Size([1, 28, 28])\n",
    "torch.Size([])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d23ccd-5e3d-441d-b434-49fd435109e3",
   "metadata": {},
   "source": [
    "Rede utilizada https://keras.io/api/applications/inceptionv3/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d8e8877-b8ec-4abc-85a7-949a4f129430",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Modelo(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Modelo, self).__init__()\n",
    "        self.linear1 = nn.Linear(28*28, 128) # camada de entrada, 784 neurônios que se ligam a 128\n",
    "        self.linear2 = nn.Linear(128, 64) # camada interna 1, 128 neurônios que se ligam a 64\n",
    "        self.linear3 = nn.Linear(64, 10) # camada interna 2, 64 neurônios que se ligam a 10\n",
    "        # para a camada de saída não é necessário definir nada pois só precisamos pegar o output da camada interna 2\n",
    "        \n",
    "    def forward(self,X):\n",
    "        X = F.relu(self.linear1(X)) # função de ativação da camada de entrada para a camada interna 1\n",
    "        X = F.relu(self.linear2(X)) # função de ativação da camada interna 1 para a camada interna 2\n",
    "        X = self.linear3(X) # função de ativação da camada interna 2 para a camada de saída, nesse caso f(x) = x\n",
    "        return F.log_softmax(X, dim=1) # dados utilizados para calcular a perda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a5b67f7-87a7-4cf3-8887-aecbe8bb37f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def treino(modelo, trainloader, device):\n",
    "    \n",
    "    otimizador = optim.SGD(modelo.parameters(), lr=0.01, momentum=0.5) # define a política de atualização dos pesos e da bias\n",
    "    inicio = time() # timer para sabermos quanto tempo levou o trino\n",
    "    \n",
    "    criterio = nn.NLLLoss() # definindo o critério para calcular a perda\n",
    "    EPOCHS = 100 # numero de epochs que o algoritmo rodará\n",
    "    modelo.train() # ativando o modo de treinamento do modelo\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        perda_acumulada = 0 # inicializaçãoda perda acumulada da epoch em questão\n",
    "        \n",
    "        for imagens, etiquetas in trainloader:\n",
    "            \n",
    "            imagens = imagens.view(imagens.shape[0], -1) # convertendo as imagens para \"vetores\" de 28*28 casas para ficarem compatíveis com a ...\n",
    "            otimizador.zero_grad() # sezando os gradientes por conta do ciclo anterior\n",
    "            \n",
    "            output = modelo(imagens.to(device)) # colocando os dados no modelo\n",
    "            perda_instantanea = criterio(output, etiquetas.to(device)) # calculando a perda da epoch em questão\n",
    "            \n",
    "            perda_instantanea.backward() # back propagation a partir da perda\n",
    "            \n",
    "            otimizador.step() # atualizando os pesos e as bias\n",
    "            \n",
    "            perda_acumulada += perda_instantanea.item() # atualização da perda acumulada\n",
    "        \n",
    "        \n",
    "        else:\n",
    "            print(\"Epoch {} - Perda resultante: {}\".format(epoch+1, perda_acumulada/len(trainloader)))\n",
    "    print(\"\\nTempo de trino (em minutos) =\", (time()-inicio)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be4bbe54-1465-405c-84ef-1e786af0d8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validacao(modelo, valloader, device):\n",
    "    conta_corretas, conta_todas = 0, 0\n",
    "    for imagens,etiquetas in valloader:\n",
    "        for i in range(len(etiquetas)):\n",
    "            img = imagens[i].view(1, 784)\n",
    "            # desativar o autograd para acelerar a validação. Grafos computacionais dinâmicos tem um custo alto de processamento\n",
    "            with torch.no_grad():\n",
    "                logs = modelo(img.to(device)) # output do modelo em escala logaritmica\n",
    "                \n",
    "                \n",
    "            ps = torch.exp(logps) # converte output para escala normal (lembrando que é um tensor)\n",
    "            probab = list(ps.cpu().numpy()[0])\n",
    "            etiqueta_pred = probab.index(max(probab)) # converte o tensor em um número, no caso, o número que o modelo previu como correto\n",
    "            etiqueta_certa = etiquetas.numpy()[1]\n",
    "            if(etiqueta_certa == etiqueta_pred): # compara a previsão com o valor correto\n",
    "                conta_corretas += 1\n",
    "            conta_todas += 1\n",
    "            \n",
    "        print(\"Total de imagens testadas =\", conta_todas)\n",
    "        print(\"\\nPrecisão do modelo = {}%\".format(conta_corretas*100/conta_todas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f02d6e5-3709-49c0-a951-c4186da4bc63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Modelo(\n",
       "  (linear1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (linear2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (linear3): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo = Modelo()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "modelo.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a33156-fd0f-4d75-980d-25f644cd072e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
